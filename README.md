Bank Transaction ETL Pipeline using Python, Pandas & Google BigQuery
Objective: Build a simple ETL pipeline to clean and analyze bank transaction data.

Tools Used:
Python, Pandas, Google BigQuery, CSV file (bank data)

ðŸ”¹ Extract:

Loaded raw bank transaction data from a CSV file using Pandas.

ðŸ”¹ Transform:

Performed data inspection (data types, missing values, nulls).

Applied data cleaning (handled missing/null values, fixed data types, formatted columns).

Filtered and refined the data to ensure accuracy and consistency.

ðŸ”¹ Load:

Exported the cleaned data and uploaded it to Google BigQuery.

Verified successful loading and used BigQuery to enable real-time querying and analytics.

ðŸ“Œ Key Concepts Covered:

Basics of ETL (Extract, Transform, Load) process.

Working with Pandas for data transformation.

Using Google BigQuery for cloud-based data storage and analysis.

Handling real-world financial data in a structured workflow.

âœ… Outcome:

Cleaned and ready-to-analyze dataset hosted in BigQuery.

The pipeline sets a foundation for building automated and scalable data solutions.
